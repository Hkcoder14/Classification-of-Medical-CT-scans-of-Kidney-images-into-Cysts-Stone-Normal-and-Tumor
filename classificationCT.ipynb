{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing dependencies and libraries for Data preprocessing and data collection\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "dataset_path = \"/Volumes/Development/kidney2.0/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\"\n",
    "categories = [\"Cyst\", \"Normal\", \"Stone\", \"Tumor\"]\n",
    "#Preprocessing of data(Resizing images, normalizing it)\n",
    "images = []\n",
    "labels = []\n",
    "img_paths = []\n",
    "\n",
    "for category_id, category in enumerate(categories):\n",
    "    folder_path = os.path.join(dataset_path, category)\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        img = cv2.resize(img, (224, 224))  # Resize to a common size\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img)\n",
    "        img_paths.append(img_path) \n",
    "        labels.append(category_id)\n",
    "        print(f\"Image path: {img_path}, Category: {category}\")\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):    \n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(categories[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "np.savez(\"preprocessed_data.npz\", X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "\n",
    "X_val_train, X_val_test, y_val_train, y_val_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Define CNN model architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(224, 224, 3)),\n",
    "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),  # Apply dropout after pooling layer\n",
    "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),  # Apply dropout after pooling layer\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.2),  # Apply dropout before output layer\n",
    "    Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val_test, y_val_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate normalized confusion matrix\n",
    "conf_matrix_norm = conf_matrix / conf_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = np.corrcoef(conf_matrix_norm)\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Classes\")\n",
    "plt.title(\"Correlation Matrix of Normalized Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "model.save(\"kidney_model.keras\")\n",
    "print(\"model saved successfully\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = \"kidney_model.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(\"Error: Unable to read the image file.\")\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, (224, 224))  # Resize to a common size\n",
    "    img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Function to predict the category of the input image\n",
    "def predict_image_category(img_path):\n",
    "    preprocessed_img = preprocess_image(img_path)\n",
    "    if preprocessed_img is None:\n",
    "        return None\n",
    "    prediction = model.predict(preprocessed_img)\n",
    "    predicted_class_index = np.argmax(prediction)\n",
    "    return predicted_class_index  # Return the predicted class index\n",
    "\n",
    "# Prompt the user to enter the image file path\n",
    "img_path = input(\"Enter the path of the image file: \")\n",
    "\n",
    "# Predict the category index of the input image\n",
    "predicted_class_index = predict_image_category(img_path)\n",
    "\n",
    "if predicted_class_index is not None:\n",
    "    # Display the predicted category index\n",
    "    print(\"Predicted class index:\", predicted_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
